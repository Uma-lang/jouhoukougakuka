<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <title>生命と情報</title>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: "Helvetica Neue", Arial, sans-serif;
            background-color: #f5f5f5;
            color: #333;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            padding: 20px;
            max-width: 1000px;
            margin: 0 auto;
        }

        h1 {
            text-align: center;
            font-size: 2.5em;
            color: #2c3e50;
            margin-bottom: 20px;
        }

        h2 {
            color: #34495e;
            border-bottom: 2px solid #020c0e;
            padding-bottom: 10px;
            margin-top: 30px;
        }

        p {
            font-size: 1.1em;
            margin-bottom: 20px;
        }

        ul,
        ol {
            margin-left: 40px;
            margin-bottom: 20px;
            line-height: 1.6;
        }

        li {
            margin-bottom: 10px;
        }

        code,
        pre {
            background-color: #ecf0f1;
            padding: 10px;
            border-radius: 5px;
            font-family: "Courier New", monospace;
        }

        pre {
            overflow-x: auto;
        }

        a {
            color: #3498db;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }



        .mathjax-display {
            text-align: center;
            margin: 20px 0;
        }

        @media screen and (min-width: 768px) {
            body {
                padding: 40px;
            }
        }
    </style>
</head>

<body>
    <h1>生命と情報</h1>

    <h2>1・3) ダーウィンが考えた進化に必要な４つの柱</h2>
    <p>集団、遺伝、多様性、選択</p>

    <h2>1・4) 進化をもたらすダイナミクスには自然淘汰のほかにどのようなものがあるか</h2>
    <p>ハーディー・ワインベルク平衡、突然変異、遺伝的浮動、移動</p>

    <h2>1・5) 進化アルゴリズムの一般的な計算行程を５つのステップを踏まえて説明せよ</h2>
    <p>まず、初期集団をランダムに生成し、各個体の適応度を評価します。次に、適応度に基づいて優れた個体を選択し、交叉により親個体の遺伝情報を組み合わせ、新しい子個体を生成します。また、突然変異によって個体の遺伝子をランダムに変更し、多様性を維持します。これらのステップを繰り返すことで、集団全体を進化させながら最適解を探索していきます。
    </p>

    <h2>2・1) ナップサック問題でお菓子のカロリー最大化のコーディング</h2>
    <p>まず、遺伝子型を設計する際に、お菓子の選択を表す遺伝子を複数持てるようにすることで、複数個の購入を表すことができる</p>

    <h2>2・2) ナップサック問題で致死遺伝子の対策</h2>
    <p>致死遺伝子の対策として、ペナルティ関数を導入し、予算超過時に適応度を大幅に低下させる。また、遺伝子の突然変異や交叉時に制約を設け、無効な遺伝子が生成されないよう調整する。</p>

    <h2>3・1) ランキング法の説明と利点</h2>
    <p>全個体を適応度に基づいて順位付けし、順位に基づいて親を選ぶ。ランキング法の利点としては、適応度の外れ値（極端に高いまたは低い値を持つ個体）の影響を受けにくいことである。ランキング法は相対的なランクに基づいて選択するため、外れ値の影響が緩和される。
    </p>

    <h2>5・1) ベルマン方程式とは</h2>
    <p>ある状態での報酬と、その後の行動による将来の報酬の合計を最大化するための方程式。強化学習で状態価値を計算する際に用いる。</p>

    <h2>5・2) TD学習とは何の価値を推定する学習法か？</h2>
    <p>TD学習とは、時間軸上連続する二つの状態の推定価値の差を用いた学習方法である。更新式は以下の通りである。V(s)←V(s)+α[R+γV(s’)-V(s)]である。ｓを状態とし、Ｖ（ｓ）はその状態における価値である。αをステップサイズパラメータ、γを学習係数、Ｒを報酬関数である。
    </p>

    <h2>5・3) SARSA学習とは何の価値を推定する学習法か？</h2>
    <p>SARSA学習では、状態ｓで行動aを選択し、次の状態s’に選択し行動a’を選択した時の価値を学習するものである。式は、π(s,a)← π(s,a)+α[R+γ π(s’,a’)- π(s
        ,a)]で表される。ｓを状態、aを選択する行動とし、π（a,ｓ）はその状態における価値である。αをステップサイズパラメータ、γを学習係数、Ｒを報酬関数である。</p>

    <h2>5・4) Q学習とは何の価値を推定する学習法か？</h2>
    <p>Ｑ学習とは、次状態s’における実際の行動選択に関わらず、状態ｓの価値を推定するものである。式は以下の通り。Q(s,a)←Q(s,a)+α[R+γ max{ Q (s’,a’)}-Q (s ,a)]
        ｓを状態、aを選択する行動とし、Ｑ（s,a）はその状態における価値である。αをステップサイズパラメータ、γを学習係数、Ｒを報酬関数である。max{ Q (s’,a’)}は次状態ｓ‘において最大の価値を示している。
    </p>

    <h2>5・5) 行動選択の方法：εグリーディとソフトマックス</h2>
    <p>εグリーディ法は、確率 ε でランダムな行動を選び、確率 \( 1 - ε \) で最も価値の高い行動を選択する。<br>
        ソフトマックス法は各行動の評価値に基づいて確率的に行動を選択する方法である。各行動に対する指数関数をとり、正規化（確率の合計が１になるように調整）する。この確率分布に基づいて行動をランダムに選択する。
        これらの行動選択手法のコンセプトは、得られている価値をもとに試行錯誤的に手を選択することである。常に最も価値の高い手を選ぶと、まだ見ぬ高い価値を持つ手があっても発見できなくなってしまうからである。
        具体的には、以下の式で計算されます：</p>
    <p>
        \[
        P(a) = \frac{\exp\left(\frac{Q(s, a)}{\tau}\right)}{\sum \exp\left(\frac{Q(s, a)}{\tau}\right)}
        \]
    </p>
    <p>ここで、</p>
    <ul>
        <li>\( P(a) \) は行動 \( a \) が選ばれる確率</li>
        <li>\( Q(s, a) \) は状態 \( s \) で行動 \( a \) をとったときの価値</li>
        <li>\( \tau \) は温度パラメータ（探索度合いを調整）</li>
    </ul>

    <h2>5・6) アクタークリティックの説明</h2>
    <p>行動選択を担当する「アクター」と、価値の評価を行う「クリティック」に分けて学習を行う。アクターが行動を決定し、クリティックがその行動の評価を行い、アクターが学習する。</p>

    <h2>6・1) 神経回路網を使うと有利な点と使わない場合の代替事例</h2>
    <p>ニューラルネットワークを使う場合の利点: 大規模なデータセットから複雑な非線形パターンを自動で学習し、高精度な予測や分類が可能です。また、画像認識や自然言語処理など幅広い分野に適用できます。</p>
    <p>使わない場合の代替案: 線形回帰、決定木、SVMなど、問題に応じたシンプルなモデルを使用。これにより、計算負荷が少なく、解釈しやすいモデルが得られるため、小規模データや明確なルールに適しています。</p>

    <h2>6・2) 発火頻度と発火間隔の例を使った説明</h2>
    <p>発火頻度とは、神経細胞が一定時間内にどれだけ発火するかを表す。これは、神経細胞の活動強度を示す指標である。例としては、視覚系のニューロンは明るい光に対して高い発火頻度を示し、暗い光に対しては、低い発火頻度を示すことがある。
        発火間隔とは、連続する発火の間隔を示す。これは、神経細胞の発火パターンのタイミングを示す。例としては、聴覚系の神経細胞は、高周波数の音に対して短い発火間隔を示し、低周波数の音に対して長い発火間隔を示す。
    </p>

    <h2>6・3) マッカローピッツのニューラルネットワークモデルの式</h2>
    <p>マッカローピッツのニューラルネットワークモデルは、各ニューロンが重み付き入力の総和と閾値を比較する単純な二値（0または1）の出力モデルです。具体的な式は以下の通りです：</p>
    <p>
        \[
        y =
        \begin{cases}
        1 & \text{if } \sum_{i=1}^{n} w_i x_i \geq \theta \\
        0 & \text{otherwise}
        \end{cases}
        \]
    </p>
    <p>ここで、</p>
    <ul>
        <li>\( y \) はニューロンの出力（0または1）</li>
        <li>\( x_i \) は各入力信号（0または1）</li>
        <li>\( w_i \) は対応する入力の重み</li>
        <li>\( \theta \) は閾値（しきい値）</li>
    </ul>
    <p>つまり、ニューロンは入力の重み付き総和が閾値以上であれば発火（出力1）、そうでなければ発火しない（出力0）という動作をします。</p>

    <h2>6・4) 活性化関数の役割</h2>
    <p>活性化関数は、ニューラルネットワークの出力を非線形に変換し、複雑なパターンを学習できるようにする。</p>

    <h2>6・5) ニューラルネットワークの学習と強化学習の違い</h2>
    <p>強化学習は、学習するエンティティが環境内で行動し、その行動に対する報酬を受け取る環境との相互作用について学習するものである。報酬を通して行動の質を評価し、より高い報酬を受け取るために最適な行動を見つけ出すことをめざす。<br>
        ニューラルネットワークの学習は教師あり学習の一部である。モデルが与えられた入力から正しい出力を予測するように学習を行い、モデルの出力と正解ラベルの間の誤差を最小化することが目的である。</p>

    <h2>6・6) ニューラルネットワークの学習システムの歴史</h2>
    <ul>
        <li>ヘッブ則 (1949): 同時に発火した神経細胞間の結合が強まる法則。</li>
        <li>パーセプトロン (1958): 単層のニューラルネットワークで線形分離問題を解く。</li>
        <li>バックプロパゲーション (1986): 誤差を逆伝播させて多層ネットワークを学習させる。</li>
        <li>ホップフィールドネットワーク (1982): 相互結合型のネットワークで、エネルギー最小化による学習。</li>
        <li>自己組織化マップ (1982): 入力データの分類を自律的に行う無教師学習。</li>
        <li>ボルツマンマシン (1985): 確率的なネットワークで、エネルギー最小化による学習を行う。</li>
        <li>δルール (Widrow・Hoff): 単純な線形回帰の誤差最小化に基づく学習則。</li>
    </ul>

    <p>ヘッブ則は、「同時に活性化されるニューロン同士の結合が強化される」というアイデアに基づいている。ニューロンAとニューロンBが同時に活性化される場合、それらの間の結合強度を増加させるというものだった。
        　パーセプトロンは、２クラスの分類問題に適した単純なモデルである。ヘッブ則に基づき、入力と重みの線形結合を計算し、その結果が閾値を超えるかどうかによって出力を決定するものである。
        　バックプロパゲーションは、誤差逆伝播法とも呼ばれ、訓練データと正解ラベルの誤差をネットワーク内に逆伝播させ、重みを微調整してネットワークを訓練するものである。
        　ホップフィールドマシンは、再帰的な結合をもつフィードバック型のニューラルネットワークで、連想メモリや最適化問題に使用される。このネットワークは、エネルギー関数を最小化するように状態を更新し、特定のパターンを記憶及び再現するためのものである。
        　自己組織化マップは、データのクラスリングや可視化に使用されるニューラルネットワークの一種である。
        　ボルツマンマシンは、確率的なニューラルネットワークであり、エネルギー関数を最小化することを目的としています。制約付きボルツマンマシンは制約付き最適化問題に使用される。
        　δルールはウィドロウ・ホフの学習則とも呼ばれ、パーセプトロンの学習ルールの一種である。予測と正解の誤差を使用して重みを調整し、訓練データに適合するようにモデルを学習する。</p>


    <h2>バックプロパゲーションの更新式</h2>
    <h1>バックプロパゲーションの簡単な説明</h1>

    <p>バックプロパゲーションは、ニューラルネットワークで誤差を減らすために、重み（つながりの強さ）やバイアス（調整用の値）を少しずつ修正していく方法です。</p>

    <h2>更新の仕組み</h2>
    <ol>
        <li><strong>誤差を計算：</strong>まず、ネットワークの出力と正解（教師データ）との差（誤差）を計算します。</li>
        <li><strong>誤差を逆方向に伝える：</strong>この誤差を出力層から入力層に向かって順々に伝えていきます。</li>
        <li><strong>重みの修正：</strong>
            <p>重み <em>w<sub>ij</sub></em> は「今の重み - 学習率 × 誤差 × 入力の値」という形で少しずつ修正されます。</p>
            <p>式で書くと：<br>
                <code>w<sub>ij</sub> ← w<sub>ij</sub> - η × δ<sub>j</sub> × a<sub>i</sub></code></p>
            <p>（ここで <em>η</em> は学習率、<em>δ<sub>j</sub></em> は誤差、<em>a<sub>i</sub></em> は入力の値）</p>
        </li>
        <li><strong>バイアスの修正：</strong>バイアスも同様に「今のバイアス - 学習率 × 誤差」で修正します。</li>
    </ol>

    <p>このプロセスを繰り返すことで、ニューラルネットワークの出力が少しずつ正解に近づいていきます。</p>

    <p>
        重みの修正量 \(w_{i,j}^{k-1, k}\) は以下のように表されます。
    </p>
    <p>
        \[
        w_{i,j}^{k-1, k} = -\epsilon \delta_j^k \phi'(x_j^k) y_i^{k-1}
        \]
    </p>
    <ul>
        <li>\( \epsilon \) ：学習率、重みを更新する際のステップサイズ。</li>
        <li>\( \delta_j^k \) ：ニューロン \( j \) の誤差項。</li>
        <li>\( \phi'(x_j^k) \) ：活性化関数の微分（シグモイド関数や ReLU などの微分が用いられます）。</li>
        <li>\( y_i^{k-1} \) ：前の層 \( k-1 \) のニューロンの出力。</li>
    </ul>
    <p>この式は、誤差に基づいて各重みをどのように更新するかを示しています。</p>

    <h3>誤差項 \( \delta_j^k \) の計算</h3>
    <p>
        誤差項 \( \delta_j^k \) が定義されています。この誤差項は、出力層か隠れ層かによって異なります。
    </p>

    <h3>1. 出力層の場合 ( \( k = m \) )</h3>
    <p>
        \[
        \delta_j^m = y_j^m - t_j
        \]
    </p>
    <ul>
        <li>\( y_j^m \) ：ネットワークの予測出力。</li>
        <li>\( t_j \) ：目標（正解）値。</li>
    </ul>

    <h3>2. 隠れ層の場合（それ以外）</h3>
    <p>
        \[
        \delta_j^k = \sum_l \delta_l^{k+1} \phi'(x_j^k) w_{j,l}^{k,k+1}
        \]
    </p>
    <ul>
        <li>これは、次の層 \( k+1 \) から逆伝播してきた誤差を用いて計算します。</li>
        <li>\( \delta_l^{k+1} \) ：次の層の誤差項。</li>
        <li>\( w_{j,l}^{k,k+1} \) ：層 \( k \) と層 \( k+1 \) を結ぶ重み。</li>
        <li>\( \phi'(x_j^k) \) ：次の層 \( k+1 \) の活性化関数の微分。</li>
    </ul>

    <h2>6・8) オーバーフィッティングとは何か？</h2>
    <p>オーバーフィッティングとは、学習したモデルが訓練データに対して過度に適応しすぎることで、新しいデータに対してうまく汎化できない状態のこと。モデルが訓練データのノイズや細かいパターンまで学習してしまうため、誤差が小さくなるが、テストデータや未知のデータに対する予測精度が低下する。
    </p>

    <h2>7・1) ライオンの群れのサイズについてのSiblyの説明</h2>
    <p>Siblyは、群れのサイズが個体の適応度に影響を与えるとし、最適な群れのサイズは個体あたりの利益が最大となる点で決まるとした。しかし実際には、社会的要因や環境の変動により、理論的に最適とされるサイズから逸脱することがあるという意見もある。
    </p>

    <h2>7・2) クレイグ・レイノルズのBoidsモデルの説明</h2>
    <p>Boidsモデルは、個体（ボイド）が周囲の個体と協調して群れ行動をするシミュレーションモデルである。3つのルールが基本で、1つは分離（個体同士が衝突しないようにする）、2つ目は整列（周囲の個体と同じ方向に動く）、3つ目は結束（群れの中心に向かう動き）。これにより群れの行動が自然に形成される。
    </p>

    <h2>8・1) Pyleが考えた生き物の食事の際の課題</h2>
    <p>Pyleは、生物が食事をする際に、次の4つの課題に直面するとした。</p>
    <ol>
        <li>どの獲物を捕食するか（Optimal Diet Choice）</li>
        <li>どのパッチ（場所）を探索するか（Optimal Patch Choice）</li>
        <li>いつパッチを離れるか（Optimal Giving Up Time）</li>
        <li>パッチ間をどう移動するか（Optimal Movement）</li>
    </ol>

    <h2>8・2) 最適メニュー理論の説明</h2>
    <p>最適メニュー理論（Optimal Diet
        Theory）は、捕食者が複数の選択肢からどの獲物を選ぶべきかを理論的に説明する。選択肢には獲物のエネルギー量や捕獲・処理にかかる時間が考慮され、特定の閾値を超えない限りより大きな獲物を狙うべきであるとされる。</p>

    <h2>8・3) 最適パッチ利用モデルの説明</h2>
    <p>最適パッチ利用モデル（Optimal Patch Use
        Model）は、捕食者がどのくらいの時間をあるパッチ（餌場）で過ごすべきかを説明する。捕食者は時間の経過とともにパッチ内の餌の捕獲率が減少するため、別のパッチに移動するタイミングを最適化する必要がある。</p>

    <h2>8・4) 腹をすかせたイトヨが餌がたくさんある狩り場に行きやすい理由</h2>
    <p>腹をすかせたイトヨは、高密度の餌場に行くことで効率的にエネルギーを補給できるからである。一方で、あまり空腹でない場合はリスクを避け、低密度の餌場でゆっくりと食事をする。これはリスクとリターンのバランスを取る行動戦略である。
    </p>

    <h2>8・5) ミツバチが少量の蜜を運搬する理由</h2>
    <p>ミツバチは、巣から遠いパッチから蜜を運ぶ際には少量の蜜しか運搬しない。これは、巣に戻る時間や労力と、蜜をたくさん運ぶことによる遅延のトレードオフを考慮した結果である。ムクドリとは異なる行動を取るのは、このトレードオフが異なるためである。
    </p>

    <h2>9・1) コホーネンの自己組織化マップのアルゴリズムの説明</h2>
    <p>コホーネンの自己組織化マップ（SOM）は、データを低次元に投影して視覚化するためのアルゴリズム。各入力データはネットワークのノードと比較され、最も近いノード（勝者）が更新される。これにより、類似したデータがネットワーク内で近くに配置されるように学習が進む。
    </p>
</body>

</html>